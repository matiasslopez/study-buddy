import os
import json
import time
import re
import unicodedata
import string
import requests  # opcional
import httpx
import streamlit as st
from dotenv import load_dotenv
from datetime import datetime

# Similitud difusa (opcional)
try:
    from rapidfuzz import fuzz
except Exception:
    fuzz = None

# ====== Config ======
load_dotenv()

# Leer API key de Secrets (Cloud) o .env (local)
OPENROUTER_API_KEY = (
    st.secrets.get("OPENROUTER_API_KEY")
    or os.getenv("OPENROUTER_API_KEY")
)

OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
DEFAULT_MODEL = "openai/gpt-4o-mini"

# Headers extra recomendados (no obligatorios) por OpenRouter
OPENROUTER_HEADERS_EXTRA = {
    # Si quer√©s, sete√° tu URL p√∫blica en Secrets como APP_URL
    "HTTP-Referer": st.secrets.get("APP_URL", ""),
    "X-Title": "Study Buddy",
}

st.set_page_config(
    page_title="üìò Study Buddy - Entrenador de parciales",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("üìò Study Buddy ‚Äî Tu compa√±ero de estudio")
st.caption(
    "Te ayuda a validar tus conocimientos, desafiarte con preguntas y acompa√±arte para lograr tu mejor performance "
    "en una presentaci√≥n o examen. Sub√≠ material (TXT/PDF/DOCX), gener√° preguntas y recib√≠ feedback con correcci√≥n flexible."
)

# ==== Gu√≠a breve de uso (plegada por defecto) ====
with st.expander("‚ùì ¬øC√≥mo lo uso? (gu√≠a r√°pida)", expanded=False):
    st.markdown(
        """
**Objetivo:** practicar con preguntas generadas a partir de tu material para medir tu preparaci√≥n y recibir feedback.

**Pasos:**
1. **Carg√° tu material:** clic en *Cargar archivo/s* y sub√≠ uno o varios documentos **TXT / PDF / DOCX** (m√°x. 5).  
2. **(Opcional) Sum√° bibliograf√≠a:** activ√° *Sumar bibliograf√≠a de Wikipedia* y/o agreg√° *Libros de referencia* indicando **t√≠tulo** y **autor/es**.  
3. **Configur√° el cuestionario:** en la barra lateral eleg√≠ **Cantidad de preguntas**, **Tipo** (opci√≥n m√∫ltiple o desarrollo) y **Dificultad** (f√°cil / media / dif√≠cil).  
4. **Gener√° preguntas:** presion√° **‚Äúüß™ Generar preguntas‚Äù**.  
5. **Respond√© y verific√°:** escrib√≠ tu respuesta (o eleg√≠ una opci√≥n) y toc√° **‚ÄúVerificar N‚Äù** para cada pregunta.  
6. **Mir√° tu resultado:** al final ver√°s tu **puntaje**, **porcentaje** y **sugerencias** sobre qu√© reforzar.  
7. **Repas√° errores:** si hubo temas flojos, us√° **‚ÄúüîÑ Repasar errores‚Äù** para generar un nuevo mini-cuestionario centrado en esos puntos.  
8. **Dejanos tu feedback:** al pie hay un link para contarnos tu experiencia y ayudarnos a mejorar.

> Tip: si cambi√°s opciones o bibliograf√≠a, pod√©s volver a generar preguntas para una nueva ronda de pr√°ctica.
"""
    )

# ====== L√≠mite diario configurable por Secrets/entorno ======
def _get_int(value, default):
    try:
        return int(str(value).strip())
    except Exception:
        return default

MAX_QUESTIONS_PER_DAY = _get_int(
    st.secrets.get("MAX_QUESTIONS_PER_DAY", os.getenv("MAX_QUESTIONS_PER_DAY", 60)),
    60
)

# ====== Control de uso diario ======
today_str = datetime.utcnow().strftime("%Y-%m-%d")
if "usage_date" not in st.session_state:
    st.session_state.usage_date = today_str
if "questions_used" not in st.session_state:
    st.session_state.questions_used = 0
if st.session_state.usage_date != today_str:
    st.session_state.usage_date = today_str
    st.session_state.questions_used = 0

# ====== Helpers ======
def call_openrouter(messages, max_tokens=800, temperature=0.6, model=DEFAULT_MODEL):
    """Cliente robusto con httpx, HTTP/1.1 y reintentos para evitar errores TLS."""
    if not OPENROUTER_API_KEY:
        raise RuntimeError(
            "No se encontr√≥ OPENROUTER_API_KEY. "
            "Carg√° el secreto en Streamlit Cloud (‚ãÆ ‚Üí Settings ‚Üí Secrets) o definilo en tu .env local."
        )

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        **OPENROUTER_HEADERS_EXTRA,
    }
    body = {
        "model": model,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature,
    }

    backoff = [0.5, 1.0, 2.0, 4.0]
    last_err = None
    for sleep_s in backoff + [0]:
        try:
            with httpx.Client(http2=False, timeout=60.0, verify=True) as client:
                r = client.post(OPENROUTER_URL, headers=headers, json=body)
                r.raise_for_status()
                data = r.json()
                return data["choices"][0]["message"]["content"]
        except Exception as e:
            last_err = e
            if sleep_s:
                time.sleep(sleep_s)
            else:
                break

    raise RuntimeError(f"Fallo al llamar a OpenRouter tras reintentos: {last_err}")

# -------- File loaders --------
@st.cache_data(show_spinner=False)
def load_txt(file_bytes: bytes) -> str:
    return file_bytes.decode("utf-8", errors="ignore")

@st.cache_data(show_spinner=False)
def load_pdf(file) -> str:
    try:
        from PyPDF2 import PdfReader
    except Exception:
        st.error("Falta PyPDF2. Instal√°: pip install PyPDF2")
        return ""
    reader = PdfReader(file)
    pages = []
    for p in reader.pages:
        try:
            pages.append(p.extract_text() or "")
        except Exception:
            pages.append("")
    return "\n".join(pages)

@st.cache_data(show_spinner=False)
def load_docx(file) -> str:
    try:
        import docx
    except Exception:
        st.error("Falta python-docx. Instal√°: pip install python-docx")
        return ""
    doc = docx.Document(file)
    return "\n".join([p.text for p in doc.paragraphs if p.text])

# ====== Normalizaci√≥n ======
def normalize_text(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize("NFKD", s)
    s = "".join(ch for ch in s if not unicodedata.combining(ch))
    s = s.lower()
    table = str.maketrans({ch: " " for ch in string.punctuation})
    s = s.translate(table)
    s = " ".join(s.split())
    return s

def best_snippet_similarity(haystack: str, needle: str):
    if not haystack or not needle:
        return 0, ""
    if fuzz is None:
        return (100, needle) if needle in haystack else (0, "")
    sim = fuzz.token_set_ratio(haystack, needle)
    snippet = (haystack[:140] + "‚Ä¶") if len(haystack) > 140 else haystack
    return sim, snippet

# ====== State ======
if "refs" not in st.session_state:
    st.session_state.refs = []
if "ref_title" not in st.session_state:
    st.session_state.ref_title = ""
if "ref_authors" not in st.session_state:
    st.session_state.ref_authors = ""
if "questions" not in st.session_state:
    st.session_state.questions = None
    st.session_state.answers = {}
    st.session_state.checked = {}

# ====== Sidebar ======
with st.sidebar:
    st.header("‚öôÔ∏è Opciones")

    q_count = st.selectbox("Cantidad de preguntas", list(range(1, 21)), index=4)
    difficulty = st.selectbox("Dificultad", ["F√°cil", "Media", "Dif√≠cil"], index=0)
    q_type = st.selectbox("Tipo de pregunta", ["Opci√≥n m√∫ltiple", "Desarrollo"])

    add_wiki = st.checkbox(
        "Sumar bibliograf√≠a de Wikipedia",
        value=False,
        help="Agrega res√∫menes breves de Wikipedia de t√©rminos detectados",
    )

    with st.expander("üìö Libros de referencia (opcional)", expanded=False):
        st.caption("Ingres√° **un libro por vez**. Indic√° *t√≠tulo* y *autores* (como aparecen en librer√≠as).")

        ref_title = st.text_input("T√≠tulo del libro", key="ref_title")
        ref_authors = st.text_input("Autor/es", key="ref_authors")

        if st.button("‚ûï Agregar referencia", use_container_width=True):
            if ref_title.strip():
                st.session_state.refs.append({"titulo": ref_title.strip(), "autores": ref_authors.strip()})
                st.session_state.ref_title = ""
                st.session_state.ref_authors = ""
                st.rerun()

        if st.button("üóëÔ∏è Vaciar lista", use_container_width=True):
            st.session_state.refs = []
            st.rerun()

        if st.session_state.refs:
            st.markdown("**Referencias cargadas:**")
            for idx, r in enumerate(list(st.session_state.refs)):
                c1, c2 = st.columns([8, 1])
                with c1:
                    st.write(f"‚Ä¢ *{r['titulo']}* ‚Äî {r['autores']}")
                with c2:
                    if st.button("‚ùå", key=f"del_ref_{idx}", help="Eliminar esta referencia"):
                        st.session_state.refs.pop(idx)
                        st.rerun()

    st.divider()
    lenient = st.checkbox("Correcci√≥n flexible (texto libre)", value=True)
    threshold = st.slider("Umbral de aceptaci√≥n (%)", 50, 95, 70) if lenient else 0
    show_diag = st.checkbox("Mostrar diagn√≥stico detallado", value=True)

    # Mostrar uso diario en la sidebar
    st.caption(f"üìä Uso diario: {st.session_state.questions_used}/{MAX_QUESTIONS_PER_DAY} preguntas")

# ====== Uploader ======
st.markdown(
    """
    <style>
    div[data-testid="stFileUploader"] {max-width: 520px; margin-left:auto; margin-right:auto;}
    section[data-testid="stFileUploaderDropzone"] {padding: 0.25rem 0.5rem;}
    </style>
    """,
    unsafe_allow_html=True,
)
c1, c2, c3 = st.columns([1, 2, 1])
with c2:
    uploaded_files = st.file_uploader(
        "üìÇ Cargar archivo/s (TXT, PDF, DOCX)",
        type=["txt", "pdf", "docx"],
        accept_multiple_files=True,
    )

# Cargar hasta 5 archivos
corpus = ""
if uploaded_files:
    texts = []
    for uploaded in uploaded_files[:5]:
        name = uploaded.name.lower()
        if uploaded.type == "text/plain" or name.endswith(".txt"):
            texts.append(load_txt(uploaded.read()))
        elif uploaded.type == "application/pdf" or name.endswith(".pdf"):
            texts.append(load_pdf(uploaded))
        else:
            texts.append(load_docx(uploaded))
    corpus = "\n\n".join(texts)
    if corpus.strip():
        st.success(f"‚úÖ {len(uploaded_files[:5])} archivo(s) cargado(s)")
    else:
        st.warning("No se pudo extraer texto de los archivos.")

# ====== Wikipedia opcional ======
def wikipedia_summary(term: str, lang: str = "es") -> str:
    try:
        import wikipedia
        wikipedia.set_lang(lang)
        return wikipedia.summary(term, sentences=2)
    except Exception:
        return ""

@st.cache_data(show_spinner=False)
def enrich_with_wikipedia(text: str, max_terms: int = 3) -> str:
    candidates = re.findall(r"\b[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±A-Z√Å√â√ç√ì√ö√ë]{3,}\b", text)
    freq = {}
    for c in candidates:
        freq[c] = freq.get(c, 0) + 1
    top = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:max_terms]
    extras = []
    for term, _ in top:
        s = wikipedia_summary(term)
        if s:
            extras.append(f"### {term}\n{s}")
    return "\n\n".join(extras)

# ====== Generate Questions ======
col1, col2 = st.columns([1, 1])
with col1:
    if st.button("üß™ Generar preguntas"):
        if not corpus.strip():
            st.warning("Sub√≠ al menos un archivo con contenido primero.")
        else:
            # Chequeo de cuota ANTES de invocar a la IA
            if st.session_state.questions_used + int(q_count) > MAX_QUESTIONS_PER_DAY:
                st.warning(
                    f"‚ö†Ô∏è Alcanzaste el l√≠mite diario de {MAX_QUESTIONS_PER_DAY} preguntas en esta sesi√≥n. "
                    "Reduc√≠ la cantidad o intent√° ma√±ana."
                )
            else:
                extra = ""
                if add_wiki:
                    with st.spinner("Buscando bibliograf√≠a de apoyo en Wikipedia..."):
                        extra = enrich_with_wikipedia(corpus)
                        if extra:
                            st.info("Se agreg√≥ bibliograf√≠a extra de Wikipedia.")

                sys_prompt = """
Sos un generador de preguntas para preparar ex√°menes.
Devolv√© SIEMPRE un JSON v√°lido con esta forma:

[
  {
    "pregunta": str,
    "opciones": [str],
    "respuesta": str,
    "explicacion": str,
    "puntos_clave": [str]
  }
]

Para "Opci√≥n m√∫ltiple": inclu√≠ 3‚Äì5 "opciones" y la correcta en "respuesta".
Para "Desarrollo": "opciones" debe ser [], y complet√° "puntos_clave" con 3‚Äì6 ideas que permitan evaluar sin literalidad.
"""

                refs_txt = ""
                if st.session_state.refs:
                    lines = [f"- {r['titulo']} ‚Äî {r['autores']}".strip() for r in st.session_state.refs]
                    refs_txt = "Referencias adicionales:\n" + "\n".join(lines)

                user_prompt = f"""
Texto base del alumno:
---
{corpus[:15000]}
---

{('Bibliograf√≠a extra:\n' + extra) if extra else ''}

{refs_txt}

Gener√° {q_count} preguntas de tipo {q_type} con dificultad {difficulty}.
En las preguntas de desarrollo, inclu√≠ "puntos_clave".
Procur√° incluir tambi√©n preguntas que vinculen conceptos del material con las referencias adicionales cuando sea pertinente.
Devolv√© JSON puro (sin comentarios ni texto extra).
"""
                with st.spinner("Generando preguntas..."):
                    try:
                        content = call_openrouter(
                            [
                                {"role": "system", "content": sys_prompt},
                                {"role": "user", "content": user_prompt},
                            ],
                            max_tokens=2000,
                        )
                        questions = json.loads(content)
                        assert isinstance(questions, list) and all("pregunta" in q for q in questions)
                        st.session_state.questions = questions
                        st.session_state.answers = {}
                        st.session_state.checked = {}
                        st.session_state.questions_used += int(q_count)  # sumar uso solo si sali√≥ ok
                        st.success("‚úÖ Preguntas listas")
                    except Exception as e:
                        msg = str(e)
                        if "401" in msg:
                            st.error("üîê 401 Unauthorized: revis√° tu OPENROUTER_API_KEY en Secrets.")
                        elif "429" in msg:
                            st.error("‚ö†Ô∏è L√≠mite de uso de la API (429). Reduc√≠ la cantidad o intent√° m√°s tarde.")
                        else:
                            st.error(f"No se pudieron generar preguntas. Detalle: {e}")

with col2:
    if st.button("üßπ Borrar todo"):
        st.session_state.questions = None
        st.session_state.answers = {}
        st.session_state.checked = {}
        st.rerun()

# ====== Render Quiz ======
if st.session_state.questions:
    st.subheader("üìö Preguntas")
    questions = st.session_state.questions
    total = len(questions)
    score = 0.0
    wrong_count = 0
    partial_count = 0
    missed_points = []
    checked_count = 0

    for i, q in enumerate(questions):
        st.markdown(f"**{i+1}. {q.get('pregunta','')}**")
        options = q.get("opciones", []) or []
        if options:
            choice = st.radio("Eleg√≠ una opci√≥n:", options, key=f"opt_{i}")
            if st.button(f"Verificar {i+1}", key=f"check_{i}"):
                st.session_state.checked[i] = True
                st.session_state.answers[i] = choice
        else:
            typed = st.text_area("Tu respuesta:", key=f"txt_{i}")
            if st.button(f"Verificar {i+1}", key=f"check_{i}"):
                st.session_state.checked[i] = True
                st.session_state.answers[i] = typed

        if st.session_state.checked.get(i):
            checked_count += 1
            is_mc = bool(options)
            if is_mc:
                ok = st.session_state.answers.get(i) == q.get("respuesta", "")
                if ok:
                    st.success(f"‚úÖ Correcto. {q.get('explicacion','')}")
                    score += 1
                else:
                    st.error(f"‚ùå Incorrecto. Correcta: {q.get('respuesta','')}. {q.get('explicacion','')}")
                    wrong_count += 1
            else:
                # ====== Evaluaci√≥n de desarrollo ======
                gold = (q.get('respuesta','') or '').strip()
                puntos = q.get('puntos_clave', []) or []
                user = (st.session_state.answers.get(i) or '').strip()

                gold_norm = normalize_text(gold)
                user_norm = normalize_text(user)

                thr = int(threshold) if lenient else 85

                passed = False
                partial = False
                details = []
                diag_rows = []
                missing = []

                # 1) Igualdad/contenci√≥n
                if gold_norm and user_norm:
                    if gold_norm == user_norm:
                        passed = True
                        details.append("Igualdad tras normalizaci√≥n.")
                    elif user_norm in gold_norm or gold_norm in user_norm:
                        passed = True
                        details.append("Contenci√≥n directa entre respuesta y soluci√≥n.")

                # 2) Cobertura de puntos clave
                coverage = 0
                covered = 0
                if not passed and puntos:
                    for p in puntos:
                        p_norm = normalize_text(p)
                        hit = False
                        sim = 0
                        snippet = ""
                        if p_norm and p_norm in user_norm:
                            hit = True
                            sim = 100
                            snippet = user[:140] + ("‚Ä¶" if len(user) > 140 else "")
                        elif fuzz is not None and p_norm:
                            sim, snippet = best_snippet_similarity(user_norm, p_norm)
                            if sim >= thr:
                                hit = True
                        diag_rows.append((p, sim, hit, snippet))
                        if hit:
                            covered += 1
                        else:
                            missing.append(p)

                    coverage = 100 * covered / max(1, len(puntos))
                    details.append(f"Cobertura de puntos clave: {coverage:.0f}% ({covered}/{len(puntos)})")
                    if coverage >= thr:
                        passed = True
                    elif coverage >= max(40, thr - 20):
                        partial = True
                    else:
                        if missing:
                            details.append("Puntos a reforzar: " + "; ".join(missing[:5]))

                # 3) Similitud global
                if not passed and fuzz is not None and gold_norm and user_norm and lenient:
                    sim_global = fuzz.token_set_ratio(user_norm, gold_norm)
                    details.append(f"Similitud global (token-set): {sim_global}%")
                    if sim_global >= thr:
                        passed = True
                    elif sim_global >= max(40, thr - 10):
                        partial = True

                # 4) Jaccard de contenido
                if not passed and gold_norm and user_norm:
                    def content_words(s):
                        return {w for w in s.split() if len(w) >= 3}
                    gw = content_words(gold_norm)
                    uw = content_words(user_norm)
                    inter = len(gw & uw)
                    union = max(1, len(gw | uw))
                    jacc = 100 * inter / union
                    details.append(f"Superposici√≥n de contenido (Jaccard): {jacc:.0f}%")
                    if jacc >= thr:
                        passed = True
                    elif jacc >= max(40, thr - 10):
                        partial = True

                if passed:
                    st.success("‚úÖ Correcto (correcci√≥n flexible)")
                    score += 1
                elif partial:
                    st.warning("üü° Parcialmente correcto")
                    score += 0.5
                    partial_count += 1
                else:
                    st.error("‚ùå A revisar (no coincide suficiente con la respuesta esperada)")
                    wrong_count += 1
                    if missing:
                        missed_points.extend(missing)

                with st.expander("Ver criterios / soluci√≥n"):
                    st.markdown("**Respuesta esperada**\n\n" + gold)
                    if puntos:
                        st.markdown("**Puntos clave**\n\n- " + "\n- ".join(puntos))
                    if details:
                        st.markdown("**Criterios**\n\n- " + "\n- ".join(details))
                    if show_diag and puntos:
                        st.markdown("**Diagn√≥stico por punto**")
                        try:
                            import pandas as pd
                            df = pd.DataFrame([
                                {"Punto clave": p, "Similitud (%)": sim, "Cubierto": "S√≠" if hit else "No", "Ejemplo": snippet}
                                for (p, sim, hit, snippet) in diag_rows
                            ])
                            st.dataframe(df, use_container_width=True)
                        except Exception:
                            for (p, sim, hit, snippet) in diag_rows:
                                st.write(f"- **{p}** ‚Üí similitud: {sim}%, cubierto: {'S√≠' if hit else 'No'}")
                                if snippet:
                                    st.caption(f"Ejemplo: {snippet}")

    # ---- Score final + feedback y repaso ----
    if any(st.session_state.checked.values()):
        st.markdown("---")
        st.subheader("üìà Resultado")
        st.write(f"Puntaje: **{score:.1f}** / **{total}**")
        st.write(f"Porcentaje: **{(score/total)*100:.1f}%**")
        st.caption("Regla: correcto = 1 punto; parcialmente correcto = 0.5 puntos.")

        # Feedback optimista si complet√≥ todas
        if checked_count == total:
            ratio = score / total if total else 0
            if ratio >= 0.85:
                st.success("üåü ¬°Excelente! Est√°s listo/a para rendir. Manten√© un repaso ligero y dorm√≠ bien antes del examen.")
            elif ratio >= 0.7:
                st.info("üí™ Buen trabajo. Reforz√° los conceptos con menor cobertura y hac√© un repaso focalizado.")
            else:
                st.warning("üöÄ Vas en camino. Repas√° los puntos clave marcados como faltantes y practic√° 3‚Äì5 preguntas adicionales.")
            if 'missed_points' in locals() and missed_points:
                uniq = {}
                for p in missed_points:
                    if p and p.strip():
                        uniq[p.strip()] = uniq.get(p.strip(), 0) + 1
                if uniq:
                    st.markdown("**Temas a reforzar (seg√∫n correcci√≥n):**")
                    for k, _ in sorted(uniq.items(), key=lambda x: x[1], reverse=True)[:8]:
                        st.write(f"‚Ä¢ {k}")

        # Repasar errores (respeta tipo y usa q_count)
        if 'missed_points' in locals() and missed_points:
            if st.button("üîÑ Repasar errores"):
                missed_text = "\n".join(f"- {p}" for p in sorted(set(missed_points)))
                sys_prompt_repaso = """
Sos un generador de preguntas para preparar ex√°menes.
Devolv√© SIEMPRE un JSON v√°lido con esta forma:

[
  {
    "pregunta": str,
    "opciones": [str],
    "respuesta": str,
    "explicacion": str,
    "puntos_clave": [str]
  }
]

Para "Opci√≥n m√∫ltiple": inclu√≠ 3‚Äì5 "opciones" y la correcta en "respuesta".
Para "Desarrollo": "opciones" debe ser [], y complet√° "puntos_clave" con 3‚Äì6 ideas evaluables.
"""
                repaso_prompt = f"""
Los siguientes temas fueron identificados como d√©biles en las respuestas del alumno:
{missed_text}

Gener√° {q_count} preguntas de tipo {q_type}
con dificultad {difficulty}, enfocadas espec√≠ficamente en estos puntos d√©biles.

Devolv√© JSON puro (sin texto extra).
"""
                try:
                    content = call_openrouter(
                        [
                            {"role": "system", "content": sys_prompt_repaso},
                            {"role": "user", "content": repaso_prompt},
                        ],
                        max_tokens=1500,
                    )
                    new_questions = json.loads(content)
                    assert isinstance(new_questions, list) and all("pregunta" in q for q in new_questions)
                    st.session_state.questions = new_questions
                    st.session_state.answers = {}
                    st.session_state.checked = {}
                    st.rerun()
                except Exception as e:
                    st.error(f"No se pudieron generar preguntas de repaso. Detalle: {e}")

# ---- Secci√≥n de feedback (siempre visible) ----
st.markdown(
    """
    ---
    **Tu feedback nos ayuda a mejorar** üôå  
    Por favor, dejanos tu opini√≥n en el siguiente formulario:  
    [‚û°Ô∏è Abrir formulario de feedback](https://docs.google.com/forms/d/e/1FAIpQLSfe4qQG9jYyKVW1EU5zgq5c6_sFd-yiujj8gvylmxfZ9-fnAA/viewform?usp=sharing&ouid=107299619610374037951)
    """
)

# ---- Footer ----
st.markdown("<hr/>", unsafe_allow_html=True)
st.caption("Motor de IA: OpenRouter (pod√©s cambiar el modelo en el c√≥digo)")
